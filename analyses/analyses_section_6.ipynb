{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba023a6a-1c85-4897-b028-ea138ce01124",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(mlr3misc)\n",
    "library(lme4)\n",
    "library(MuMIn)\n",
    "library(lmerTest)\n",
    "library(dplyr)\n",
    "library(stringr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88facc1-482b-4ead-9286-ca902c7c4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table_glmm = function(model) {\n",
    "  coefs = summary(model)$coefficients\n",
    "  coefs_df = as.data.frame(coefs)\n",
    "  \n",
    "  coefs_df$Predictor = rownames(coefs_df)\n",
    "  \n",
    "  format_p = function(p) {\n",
    "    if (p < 0.001) {\n",
    "      return(\"$<0.001$\")\n",
    "    } else {\n",
    "      return(sprintf(\"$%.3f$\", p))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  latex_rows = coefs_df %>%\n",
    "    mutate(\n",
    "      Estimate = sprintf(\"%.6f\", Estimate),\n",
    "      `Std. Error` = sprintf(\"%.6f\", `Std. Error`),\n",
    "      `z value` = sprintf(\"%.3f\", `z value`),\n",
    "      `Pr(>|z|)` = sapply(`Pr(>|z|)`, format_p)\n",
    "    ) %>%\n",
    "    transmute(\n",
    "      line = sprintf(\"    %s & %s & %s & %s & %s \\\\\\\\\", \n",
    "                     Predictor, Estimate, `Std. Error`, `z value`, `Pr(>|z|)`))\n",
    "    \n",
    "  cat(\"\\\\begin{tabular}{lrrrr}\\n\")\n",
    "  cat(\"    \\\\toprule\\n\")\n",
    "  cat(\"    Predictor & Estimate & Std. Error & $z$ value & $p$-value \\\\\\\\\\n\")\n",
    "  cat(\"    \\\\midrule\\n\")\n",
    "  cat(paste(latex_rows$line, collapse = \"\\n\"), \"\\n\")\n",
    "  cat(\"    \\\\bottomrule\\n\")\n",
    "  cat(\"\\\\end{tabular}\\n\")\n",
    "}\n",
    "\n",
    "latex_table_lmm = function(model) {\n",
    "  coefs = summary(model)$coefficients\n",
    "  coefs_df = as.data.frame(coefs)\n",
    "  \n",
    "  coefs_df$Predictor = rownames(coefs_df)\n",
    "  \n",
    "  format_p = function(p) {\n",
    "    if (p < 0.001) {\n",
    "      return(\"$<0.001$\")\n",
    "    } else {\n",
    "      return(sprintf(\"$%.3f$\", p))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  latex_rows = coefs_df %>%\n",
    "    mutate(\n",
    "      Estimate = sprintf(\"%.3e\", Estimate),\n",
    "      `Std. Error` = sprintf(\"%.3e\", `Std. Error`),\n",
    "      df = sprintf(\"%.3e\", df),\n",
    "      `t value` = sprintf(\"%.3f\", `t value`),\n",
    "      `Pr(>|t|)` = sapply(`Pr(>|t|)`, format_p)\n",
    "    ) %>%\n",
    "    transmute(\n",
    "      line = sprintf(\"    %s & %s & %s & %s & %s & %s \\\\\\\\\",\n",
    "                     Predictor, Estimate, `Std. Error`, df, `t value`, `Pr(>|t|)`))\n",
    "  \n",
    "  cat(\"\\\\begin{tabular}{lrrrrr}\\n\")\n",
    "  cat(\"    \\\\toprule\\n\")\n",
    "  cat(\"    Predictor & Estimate & Std. Error & df & $t$ value & $p$-value \\\\\\\\\\n\")\n",
    "  cat(\"    \\\\midrule\\n\")\n",
    "  cat(paste(latex_rows$line, collapse = \"\\n\"), \"\\n\")\n",
    "  cat(\"    \\\\bottomrule\\n\")\n",
    "  cat(\"\\\\end{tabular}\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132256f-6c8b-4542-8bd4-c79f242aaf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = dir(\"csvs/\")\n",
    "files = files[sapply(files, grepl, pattern = \"reshuffling\")]\n",
    "data = map_dtr(paste0(\"csvs/\", files), function(x) {\n",
    "  tmp = fread(x)\n",
    "  tmp[, c(\"seed\", \"data_id\", \"repeat\", \"metric\", \"resampling\", \"reshuffled\", \"retrained\", \"classifier\", \"optimizer\", \"train_valid_size\",\n",
    "          \"overtuning\", \"overtuning_relative\", \"iteration\", \"final_iteration\", \"no_progress\", \"meta_overfitting\", \"test_regret\")]\n",
    "}, .fill = TRUE)\n",
    "data = data[metric != \"balanced_accuracy\"]\n",
    "data[no_progress == TRUE, overtuning_relative := 0]\n",
    "factors = c(\"seed\", \"data_id\", \"repeat\", \"metric\", \"resampling\", \"reshuffled\", \"retrained\", \"classifier\", \"optimizer\", \"train_valid_size\")\n",
    "data[, (factors) := lapply(.SD, as.factor), .SDcols = factors]\n",
    "data[, metric := relevel(metric, ref = \"accuracy\")]\n",
    "data[, resampling := relevel(resampling, ref = \"holdout\")]\n",
    "data[, reshuffled := relevel(reshuffled, ref = \"FALSE\")]\n",
    "data[, retrained := relevel(retrained, ref = \"TRUE\")]\n",
    "data[, classifier := relevel(classifier, ref = \"logreg\")]\n",
    "data[, optimizer := relevel(optimizer, ref = \"random\")]\n",
    "data[, overtuning_nonzero := overtuning > 1e-3]\n",
    "data[, log_overtuning := log(overtuning)]\n",
    "data[, log_overtuning_relative := log(overtuning_relative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ce2e3-514e-46ef-8f93-e7725421098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search retrained not reshuffled\n",
    "data1 = data[iteration %in% seq(0, 500, by = 10)[-1] & retrained == TRUE & reshuffled == FALSE & optimizer == \"random\", ]\n",
    "data1[, budget := iteration / 500]\n",
    "\n",
    "# predict probability of non-zero overtuning\n",
    "glmm1_0 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + metric + classifier + resampling + train_valid_size, data = data1, family = binomial)\n",
    "glmm1_1 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size, data = data1, family = binomial)\n",
    "anova(glmm1_0, glmm1_1)\n",
    "\n",
    "# for non-zero overtuning model log_overtuning_relative\n",
    "lmm1_0 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + metric + classifier + resampling + train_valid_size, data = data1[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "lmm1_1 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size, data = data1[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "anova(lmm1_0, lmm1_1)\n",
    "\n",
    "# meta overfitting and test regret\n",
    "of_lmm1 = lmer(meta_overfitting ~ (1 | data_id) + (1 | seed) + metric + classifier + resampling + train_valid_size, data = data1[iteration == 500, ])\n",
    "tr_lmm1 = lmer(test_regret ~ (1 | data_id) + (1 | seed) + metric + classifier + resampling + train_valid_size, data = data1[iteration == 500, ])\n",
    "rm(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef531343-828d-4d07-bfc4-8ccd1b2866f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table_glmm(glmm1_1)\n",
    "latex_table_lmm(lmm1_1)\n",
    "latex_table_lmm(of_lmm1)\n",
    "latex_table_lmm(tr_lmm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15cc4f9-0279-4df6-8329-e1028ea056ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bo retrained not reshuffled\n",
    "data2 = data[iteration %in% seq(0, 250, by = 10)[-1] & metric == \"auc\" & retrained == TRUE & reshuffled == FALSE & optimizer != \"hebo_makarova\"]\n",
    "data2[, budget := iteration / 250]\n",
    "\n",
    "# predict probability of non-zero overtuning\n",
    "glmm2_0 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + classifier + resampling + train_valid_size, data = data2, family = binomial)\n",
    "glmm2_1 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + classifier + resampling + train_valid_size + optimizer, data = data2, family = binomial)\n",
    "anova(glmm2_0, glmm2_1)\n",
    "\n",
    "# for non-zero overtuning model log_overtuning_relative\n",
    "lmm2_0 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + classifier + resampling + train_valid_size, data = data2[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "lmm2_1 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + classifier + resampling + train_valid_size + optimizer, data = data2[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "anova(lmm2_0, lmm2_1)\n",
    "\n",
    "# meta overfitting and test regret\n",
    "of_lmm2 = lmer(meta_overfitting ~ (1 | data_id) + (1 | seed) + classifier + resampling + train_valid_size + optimizer, data = data2[iteration == 250, ])\n",
    "tr_lmm2 = lmer(test_regret ~ (1 | data_id) + (1 | seed) + classifier + resampling + train_valid_size + optimizer, data = data2[iteration == 250, ])\n",
    "rm(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d16db9-b719-496e-981e-b2f829f28429",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table_glmm(glmm2_1)\n",
    "latex_table_lmm(lmm2_1)\n",
    "latex_table_lmm(of_lmm2)\n",
    "latex_table_lmm(tr_lmm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264dd774-fc3c-4826-9895-888f88e7bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hebo vs. hebo hebo makarova early stopping cv retrained not reshuffled\n",
    "data3 = data[final_iteration == TRUE & metric == \"auc\" & retrained == TRUE & reshuffled == FALSE & optimizer %in% c(\"hebo\", \"hebo_makarova\") & resampling == \"cv\"]\n",
    "\n",
    "# predict probability of non-zero overtuning\n",
    "glmm3_0 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + classifier + train_valid_size, data = data3, family = binomial)\n",
    "glmm3_1 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + classifier + train_valid_size + optimizer, data = data3, family = binomial)\n",
    "anova(glmm3_0, glmm3_1)\n",
    "\n",
    "# for non-zero overtuning model log_overtuning_relative\n",
    "lmm3_0 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + classifier + train_valid_size, data = data3[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "lmm3_1 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + + classifier + train_valid_size + optimizer, data = data3[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "anova(lmm3_0, lmm3_1)\n",
    "\n",
    "# meta overfitting and test regret\n",
    "of_lmm3 = lmer(meta_overfitting ~ (1 | data_id) + (1 | seed) + classifier + train_valid_size + optimizer, data = data3[iteration == 250, ])\n",
    "tr_lmm3 = lmer(test_regret ~ (1 | data_id) + (1 | seed) + classifier + train_valid_size + optimizer, data = data3[iteration == 250, ])\n",
    "rm(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36358a31-a6f3-4f46-8b60-6f5251ed74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table_glmm(glmm3_1)\n",
    "latex_table_lmm(lmm3_1)\n",
    "latex_table_lmm(of_lmm3)\n",
    "latex_table_lmm(tr_lmm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c80dee-7241-48dd-a757-b9095fc20b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search retrained, reshuffled vs. not\n",
    "data4 = data[iteration %in% seq(0, 500, by = 10)[-1] & retrained == TRUE & optimizer == \"random\", ]\n",
    "data4[, budget := iteration / 500]\n",
    "\n",
    "# predict probability of non-zero overtuning\n",
    "glmm4_0 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size, data = data4, family = binomial)\n",
    "glmm4_1 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size + reshuffled, data = data4, family = binomial)\n",
    "anova(glmm4_0, glmm4_1)\n",
    "\n",
    "# for non-zero overtuning model log_overtuning_relative\n",
    "lmm4_0 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size, data = data4[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "lmm4_1 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size + reshuffled, data = data4[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "anova(lmm4_0, lmm4_1)\n",
    "\n",
    "# meta overfitting and test regret\n",
    "of_lmm4 = lmer(meta_overfitting ~ (1 | data_id) + (1 | seed) + metric + classifier + resampling + train_valid_size + reshuffled, data = data4[iteration == 500, ])\n",
    "tr_lmm4 = lmer(test_regret ~ (1 | data_id) + (1 | seed) + metric + classifier + resampling + train_valid_size + reshuffled, data = data4[iteration == 500, ])\n",
    "rm(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006f442-6c75-454d-ab7e-aabfe44a08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table_glmm(glmm4_1)\n",
    "latex_table_lmm(lmm4_1)\n",
    "latex_table_lmm(of_lmm4)\n",
    "latex_table_lmm(tr_lmm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9b325-deb2-493d-bca5-d0f28176e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search retrained, reshuffled vs. not, holdout auc\n",
    "data5 = data[iteration %in% seq(0, 500, by = 10)[-1] & retrained == TRUE & optimizer == \"random\" & resampling == \"holdout\" & metric == \"auc\", ]\n",
    "data5[, budget := iteration / 500]\n",
    "\n",
    "# predict probability of non-zero overtuning\n",
    "glmm5_0 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + classifier + train_valid_size, data = data5, family = binomial)\n",
    "glmm5_1 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + classifier + train_valid_size + reshuffled, data = data5, family = binomial)\n",
    "anova(glmm5_0, glmm5_1)\n",
    "\n",
    "# for non-zero overtuning model log_overtuning_relative\n",
    "lmm5_0 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + classifier + train_valid_size, data = data5[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "lmm5_1 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + classifier + train_valid_size + reshuffled, data = data5[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "anova(lmm5_0, lmm5_1)\n",
    "\n",
    "# meta overfitting and test regret\n",
    "of_lmm5 = lmer(meta_overfitting ~ (1 | data_id) + (1 | seed) + classifier + train_valid_size + reshuffled, data = data5[iteration == 500, ])\n",
    "tr_lmm5 = lmer(test_regret ~ (1 | data_id) + (1 | seed) + classifier + train_valid_size + reshuffled, data = data5[iteration == 500, ])\n",
    "rm(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c755f-93ae-4e06-a2b9-8b70324538fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table_glmm(glmm5_1)\n",
    "latex_table_lmm(lmm5_1)\n",
    "latex_table_lmm(of_lmm5)\n",
    "latex_table_lmm(tr_lmm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576867c8-9a1d-4a5e-b463-be646d0029ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search not reshufled, retrained vs. not retrained\n",
    "data6 = data[iteration %in% seq(0, 500, by = 10)[-1] & reshuffled == FALSE & optimizer == \"random\", ]\n",
    "data6[, budget := iteration / 500]\n",
    "\n",
    "# predict probability of non-zero overtuning\n",
    "glmm6_0 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size, data = data6, family = binomial)\n",
    "glmm6_1 = glmer(overtuning_nonzero ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size + retrained, data = data6, family = binomial)\n",
    "anova(glmm6_0, glmm6_1)\n",
    "\n",
    "# for non-zero overtuning model log_overtuning_relative\n",
    "lmm6_0 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size, data = data6[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "lmm6_1 = lmer(log_overtuning_relative ~ (1 | data_id) + (1 | seed) + budget + I(budget^2) + metric + classifier + resampling + train_valid_size + retrained, data = data6[overtuning_nonzero == TRUE & no_progress == FALSE, ])\n",
    "anova(lmm6_0, lmm6_1)\n",
    "\n",
    "# meta overfitting and test regret\n",
    "of_lmm6 = lmer(meta_overfitting ~ (1 | data_id) + (1 | seed) + metric + classifier + resampling + train_valid_size + retrained, data = data6[iteration == 500, ])\n",
    "tr_lmm6 = lmer(test_regret ~ (1 | data_id) + (1 | seed) + metric + classifier + resampling + train_valid_size + retrained, data = data6[iteration == 500, ])\n",
    "rm(data6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd04bac4-d8ef-4d1d-bb9e-57470e6b819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table_glmm(glmm6_1)\n",
    "latex_table_lmm(lmm6_1)\n",
    "latex_table_lmm(of_lmm6)\n",
    "latex_table_lmm(tr_lmm6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
